{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWKAve_H-bp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oASQYFTFkbPS"
      },
      "source": [
        "Step 1: Upload or Collect Video Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FSrGgiSCSQx",
        "outputId": "bd8a2dc9-edd3-4eb6-c72b-1c082be37271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe\n",
        "!pip install pandas\n",
        "!pip install  numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPTPudmnYBfR",
        "outputId": "fb4ce9a0-f514-4381-d884-6bf92f43238c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['push-up', 'shoulder press', 'squat', 'barbell biceps curl', 'lstm_model222.keras', 'lstm_model29.keras', 'lstm_model33.keras', 'model12.keras', 'model13.keras']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "output_csv = '/content/drive/MyDrive/output/keypoints6.csv'\n",
        "data_path = '/content/drive/MyDrive/SportActivityDataset/'\n",
        "activities = os.listdir(data_path)\n",
        "print(activities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxwkrfbTkC2y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mediapipe as mp\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Initialisation MediaPipe\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "# les Landmarks importants\n",
        "IMPORTANT_LMS = [\n",
        "    \"NOSE\",\n",
        "    \"LEFT_SHOULDER\",\n",
        "    \"RIGHT_SHOULDER\",\n",
        "    \"RIGHT_ELBOW\",\n",
        "    \"LEFT_ELBOW\",\n",
        "    \"RIGHT_WRIST\",\n",
        "    \"LEFT_WRIST\",\n",
        "    \"LEFT_HIP\",\n",
        "    \"RIGHT_HIP\",\"RIGHT_KNEE\",\"LEFT_KNEE\",\"RIGHT_ANKLE\",\"LEFT_ANKLE\"\n",
        "]\n",
        "#les  angles importants\n",
        "ANGLE_JOINTS = [\n",
        "    (\"LEFT_SHOULDER\", \"LEFT_ELBOW\", \"LEFT_WRIST\"),\n",
        "    (\"RIGHT_SHOULDER\", \"RIGHT_ELBOW\", \"RIGHT_WRIST\"),\n",
        "    (\"LEFT_HIP\", \"LEFT_KNEE\", \"LEFT_ANKLE\"),\n",
        "    (\"RIGHT_HIP\", \"RIGHT_KNEE\", \"RIGHT_ANKLE\")\n",
        "]\n",
        "# Création les colonnes du CSV\n",
        "angle_headers = [f\"{a}_{b}_{c}_angle\" for a, b, c in ANGLE_JOINTS]\n",
        "HEADERS = [\"label\"]\n",
        "\n",
        "for lm in IMPORTANT_LMS:\n",
        "    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]\n",
        "\n",
        "HEADERS = HEADERS+ angle_headers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GFImorYkjVO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N17App5-j-a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "#fonction to rescale the frame\n",
        "def rescale_frame(frame, percent=50):\n",
        "    width = int(frame.shape[1] * percent / 100)\n",
        "    height = int(frame.shape[0] * percent / 100)\n",
        "    dim = (width, height)\n",
        "    return cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
        "# Fonction pour extraire les keypoints\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Fonction pour extraire les keypoints d'une frame (utiliser dans le test)\n",
        "def extract_keypoints(image):\n",
        "    with mp_pose.Pose(static_image_mode=True) as pose:\n",
        "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        if not results.pose_landmarks:\n",
        "            return None\n",
        "\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "        keypoints = []\n",
        "\n",
        "        for lm in IMPORTANT_LMS:\n",
        "            point = landmarks[mp_pose.PoseLandmark[lm].value]\n",
        "            keypoints.append([point.x, point.y, point.z, point.visibility])\n",
        "\n",
        "        normalized_keypoints = normalize_keypoints(keypoints)\n",
        "        normalized_keypoints = np.array(normalized_keypoints).flatten()\n",
        "\n",
        "        # Calculate angles\n",
        "        angles = []\n",
        "        for joint1, joint2, joint3 in ANGLE_JOINTS:\n",
        "            a = landmarks[mp_pose.PoseLandmark[joint1].value]\n",
        "            b = landmarks[mp_pose.PoseLandmark[joint2].value]\n",
        "            c = landmarks[mp_pose.PoseLandmark[joint3].value]\n",
        "\n",
        "            angle = calculate_angle([a.x, a.y], [b.x, b.y], [c.x, c.y])\n",
        "            angles.append(angle)\n",
        "\n",
        "        # Concatenate keypoints and angles\n",
        "        all_features = np.concatenate([normalized_keypoints, angles])\n",
        "\n",
        "        return all_features\n",
        "\n",
        "\n",
        "\n",
        "# Fonction pour préparer la séquence des keypoints (cette fonction est utiliser dans le test)\n",
        "def prepare_sequence(video_path, sequence_length=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Erreur lors de l'ouverture de la vidéo.\")\n",
        "        return None\n",
        "\n",
        "    sequence = []\n",
        "\n",
        "    success, frame = cap.read()\n",
        "    while success:\n",
        "        keypoints = extract_features(frame)\n",
        "        if keypoints is not None:\n",
        "            sequence.append(keypoints)\n",
        "\n",
        "        if len(sequence) == sequence_length:\n",
        "            cap.release()\n",
        "            break\n",
        "\n",
        "        success, frame = cap.read()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if len(sequence) == sequence_length:\n",
        "        return np.array(sequence)  # Retourne une séquence complète de keypoints\n",
        "    else:\n",
        "        return None  # Si la séquence est trop courte\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHGJuxNo6cmE",
        "outputId": "f8191353-d8c8-4648-ea55-e97551149e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['label', 'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle', 'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle', 'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle', 'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle']\n"
          ]
        }
      ],
      "source": [
        "print(HEADERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVRyBPPqkxnL"
      },
      "source": [
        "Step 4: Normalize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0ZNl9ZDkHEs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#normalizing keypoints coordinations\n",
        "def normalize_keypoints(keypoints):\n",
        "    keypoints = np.array(keypoints)\n",
        "    return (keypoints - np.min(keypoints)) / (np.max(keypoints) - np.min(keypoints))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTZPEHLaib5F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Initialiser le fichier CSV avec les headers si non existant\n",
        "def init_csv(dataset_path: str):\n",
        "    if os.path.exists(dataset_path):\n",
        "        return  # Ne rien faire si le fichier existe déjà\n",
        "    with open(dataset_path, mode=\"w\", newline=\"\") as f:\n",
        "        csv_writer = csv.writer(f)\n",
        "        os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
        "        csv_writer.writerow(HEADERS)\n",
        "\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"\n",
        "    Calculate the angle between three points\n",
        "    a, b, c are each a list or array of [x, y]\n",
        "    Returns the angle in degrees\n",
        "    \"\"\"\n",
        "    a = np.array(a[:2])  # Only x and y\n",
        "    b = np.array(b[:2])\n",
        "    c = np.array(c[:2])\n",
        "\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "\n",
        "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
        "\n",
        "    return np.degrees(angle)\n",
        "\n",
        "# Enregistrer les keypoints + label dans le CSV\n",
        "def export_landmark_to_csv(dataset_path: str, results, label: str):\n",
        "    try:\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "        keypoints = []\n",
        "\n",
        "        for lm in IMPORTANT_LMS:\n",
        "            point = landmarks[mp_pose.PoseLandmark[lm].value]\n",
        "            keypoints.append([point.x, point.y, point.z, point.visibility])\n",
        "            normalized_keypoints = normalize_keypoints(keypoints)\n",
        "\n",
        "        keypoints_flat = list(np.array(normalized_keypoints).flatten())\n",
        "\n",
        "        # Add angle calculations\n",
        "        angles = []\n",
        "        for joint1, joint2, joint3 in ANGLE_JOINTS:\n",
        "            a = landmarks[mp_pose.PoseLandmark[joint1].value]\n",
        "            b = landmarks[mp_pose.PoseLandmark[joint2].value]\n",
        "            c = landmarks[mp_pose.PoseLandmark[joint3].value]\n",
        "\n",
        "            angle = calculate_angle(\n",
        "                [a.x, a.y], [b.x, b.y], [c.x, c.y]\n",
        "            )\n",
        "            angles.append(angle)\n",
        "\n",
        "        #all_features = [label] + keypoints_flat + angles\n",
        "        all_features = [label]+[landmarks[mp_pose.PoseLandmark[lm].value].x,landmarks[mp_pose.PoseLandmark[lm].value].y]+ angles # utiliser dans un test (à supprimer !!)\n",
        "        with open(dataset_path, mode=\"a\", newline=\"\") as f:\n",
        "            csv_writer = csv.writer(f)\n",
        "            csv_writer.writerow(all_features)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Erreur:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Anf4amo7Tr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# Extraire les frames et enregistrer les keypoints dans le CSV\n",
        "def process_video(video_path, output_csv):\n",
        "    # Label = nom du dossier parent (= activité)\n",
        "    activity_label = os.path.basename(os.path.dirname(video_path))\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    pose = mp_pose.Pose()\n",
        "    while True:\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = pose.process(image_rgb)\n",
        "\n",
        "            if results.pose_landmarks:\n",
        "                  export_landmark_to_csv(output_csv, results, activity_label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    pose.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6GMT400vNT6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJr0H2Nfnwo8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Initialisation du fichier CSV une seule fois\n",
        "def create_the_csv_file():\n",
        "\n",
        " for activity in activities:\n",
        "    activity_path = os.path.join(data_path, activity)\n",
        "    videos = os.listdir(activity_path)\n",
        "    for video in videos:\n",
        "        video_path = os.path.join(activity_path, video)\n",
        "        process_video(video_path, output_csv)\n",
        "        print(\"Le dataset   des keypoints a été créé for \"+video_path)\n",
        "    print(\"Le dataset   des keypoints a été créé avec succès fro \"+activity)\n",
        " print(\"Le dataset des keypoints a été créé avec succès !\")\n",
        " return output_csv\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAGoquP3yIh9"
      },
      "source": [
        "2. Préparation des données pour le modèle  dans la forme deq sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04rWaja6fY1P"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Define le as a global variable\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Charger le dataset\n",
        "def prepare_data(output_csv):\n",
        "    df = pd.read_csv(output_csv)\n",
        "\n",
        "    # Extraire les features et labels\n",
        "    X = df.drop('label', axis=1).values\n",
        "    y = df['label'].values\n",
        "\n",
        "    # Encoder les labels using the global le\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Paramètres\n",
        "    sequence_length = 20  # nombre de frames par séquence\n",
        "\n",
        "    # Construction des séquences cohérentes\n",
        "    X_sequences = []\n",
        "    y_sequences = []\n",
        "\n",
        "    # On parcourt les données pour créer des séquences de frames du même label\n",
        "    for i in range(len(X) - sequence_length):\n",
        "        # Vérifier que toutes les frames appartiennent au même label\n",
        "        if len(set(y[i:i+sequence_length])) == 1:\n",
        "            X_sequences.append(X[i:i+sequence_length])\n",
        "            y_sequences.append(y_encoded[i])\n",
        "\n",
        "    X_sequences = np.array(X_sequences)\n",
        "    y_sequences = np.array(y_sequences)\n",
        "\n",
        "    print(\"Shape des données LSTM : \", X_sequences.shape)  # (nb_sequences, 30, nb_features)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation du premier modèle LSTM"
      ],
      "metadata": {
        "id": "vnKbAhlfpBdp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPu3H3zNyknX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Architecture du modèle LSTM\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, return_sequences=True, activation='tanh', input_shape=(sequence_length, X_train.shape[2])))\n",
        "    model.add(LSTM(128, return_sequences=False, activation='tanh'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(len(le.classes_), activation='softmax'))\n",
        "    # Compilation\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train, X_test, y_test):\n",
        "# Entraînement avec batch_size\n",
        "  model.fit(X_train, y_train,\n",
        "          epochs=20,\n",
        "          batch_size=20,  # par exemple\n",
        "          validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tester le premier modèle\n"
      ],
      "metadata": {
        "id": "BdlB2gzgpMIb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk0lpD-D0ehN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whTZz5HIUlT_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "import mediapipe as mp\n",
        "\n",
        "# fonction pour faire la prédiction\n",
        "def predict_activity(video_path,model):\n",
        "\n",
        "# Préparer la séquence de keypoints\n",
        "  sequence = prepare_sequence(video_path)\n",
        "\n",
        "  if sequence is not None:\n",
        "    # Reshaper la séquence pour qu'elle soit compatible avec l'entrée du modèle LSTM\n",
        "    sequence = sequence.reshape(1, sequence.shape[0], sequence.shape[1])  # (1, 30, 36)\n",
        "\n",
        "    # Prédiction\n",
        "    prediction = model.predict(sequence)\n",
        "\n",
        "    # Décodage du label\n",
        "    predicted_label = np.argmax(prediction, axis=1)\n",
        "    predicted_label = le.inverse_transform(predicted_label)\n",
        "\n",
        "    # Afficher le résultat\n",
        "     # Décodage du label avec l'encodeur\n",
        "    print(f\"L'activité prédite est : {predicted_label}\")\n",
        "  else:\n",
        "    print(\"La séquence est trop courte ou aucun keypoint détecté dans la vidéo.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_a8p38MN2c4"
      },
      "outputs": [],
      "source": [
        "#preparing train and test data\n",
        "\n",
        "#output_csv = '/content/drive/MyDrive/output/keypoints7.csv'\n",
        "\n",
        "#print(X_train.shape[2])\n",
        "#print(y_test[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T0e4D2TPOJg"
      },
      "outputs": [],
      "source": [
        "#create_lstm_model\n",
        "#model=create_lstm_model(X_train.shape)\n",
        "#train the model\n",
        "#train_model(model, X_train, y_train, X_test, y_test)\n",
        "#save the model\n",
        "#model.save('/content/drive/MyDrive/SportActivityDataset/DATA/final_lstm_mode.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otATEH_KXjws",
        "outputId": "83d06b04-0299-40a4-e15e-d2b5b7c4e632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "sequence_length=30\n",
        "#load the model\n",
        "\n",
        "le.fit_transform(['barbell biceps curl', 'push-up', 'shoulder press', 'squat'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualize the data and clean it for better results"
      ],
      "metadata": {
        "id": "ZZBsBEzups1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCfXD2xjAgOM",
        "outputId": "88b10c15-3dd8-4494-9c21-5794164ed37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x',\n",
            "       'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v',\n",
            "       'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z',\n",
            "       'right_shoulder_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z',\n",
            "       'right_elbow_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z',\n",
            "       'left_elbow_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z',\n",
            "       'right_wrist_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z',\n",
            "       'left_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v',\n",
            "       'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v',\n",
            "       'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v',\n",
            "       'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v',\n",
            "       'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v',\n",
            "       'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v',\n",
            "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle',\n",
            "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle',\n",
            "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle',\n",
            "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle'],\n",
            "      dtype='object')\n",
            "['barbell biceps curl' 'push-up' 'shoulder press' 'squat']\n",
            "                label    nose_x    nose_y    nose_z    nose_v  \\\n",
            "28565  shoulder press  0.578683  0.477942  0.185670  0.868902   \n",
            "28566  shoulder press  0.575887  0.474537  0.196246  0.865325   \n",
            "28567  shoulder press  0.574833  0.472620  0.195467  0.863809   \n",
            "28568  shoulder press  0.575136  0.472969  0.194872  0.863441   \n",
            "28569  shoulder press  0.571817  0.468718  0.190299  0.862449   \n",
            "\n",
            "       left_shoulder_x  left_shoulder_y  left_shoulder_z  left_shoulder_v  \\\n",
            "28565         0.624617         0.568095         0.261009         0.868879   \n",
            "28566         0.622518         0.564100         0.257165         0.865301   \n",
            "28567         0.621705         0.562246         0.253842         0.863785   \n",
            "28568         0.622249         0.562573         0.252141         0.863416   \n",
            "28569         0.619648         0.559179         0.248959         0.862423   \n",
            "\n",
            "       right_shoulder_x  ...  right_ankle_z  right_ankle_v  left_ankle_x  \\\n",
            "28565          0.551125  ...       0.281446       0.530271      0.552430   \n",
            "28566          0.548420  ...       0.285338       0.523949      0.550682   \n",
            "28567          0.547522  ...       0.279107       0.517795      0.550711   \n",
            "28568          0.547899  ...       0.273700       0.512834      0.553029   \n",
            "28569          0.544338  ...       0.267387       0.504688      0.551583   \n",
            "\n",
            "       left_ankle_y  left_ankle_z  left_ankle_v  \\\n",
            "28565           1.0      0.122351      0.805174   \n",
            "28566           1.0      0.115982      0.791783   \n",
            "28567           1.0      0.112505      0.778751   \n",
            "28568           1.0      0.110965      0.766617   \n",
            "28569           1.0      0.107670      0.753499   \n",
            "\n",
            "       LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle  \\\n",
            "28565                                  19.083937   \n",
            "28566                                  17.064076   \n",
            "28567                                  16.312477   \n",
            "28568                                  16.257691   \n",
            "28569                                  17.379431   \n",
            "\n",
            "       RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle  \\\n",
            "28565                                     36.496826   \n",
            "28566                                     36.592782   \n",
            "28567                                     36.899752   \n",
            "28568                                     37.181749   \n",
            "28569                                     37.214496   \n",
            "\n",
            "       LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle  \\\n",
            "28565                           163.673577   \n",
            "28566                           164.679290   \n",
            "28567                           164.503712   \n",
            "28568                           164.378991   \n",
            "28569                           164.677381   \n",
            "\n",
            "       RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle  \n",
            "28565                              124.751898  \n",
            "28566                              123.877309  \n",
            "28567                              123.368707  \n",
            "28568                              122.456429  \n",
            "28569                              121.494714  \n",
            "\n",
            "[5 rows x 57 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/output/keypoints6.csv')\n",
        "print(df.columns)\n",
        "data=df[df['label']!='hammer curl']\n",
        "print(data['label'].unique())\n",
        "print(data[data['label']=='shoulder press'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "changer la structure de data pour un meilleur entrainement"
      ],
      "metadata": {
        "id": "Vv4G8zAQqOlJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA1gOZcwNmAs",
        "outputId": "85958862-3b02-40e2-d1a4-47a4bec57ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 label    nose_x    nose_y  left_shoulder_x  left_shoulder_y  \\\n",
            "0  barbell biceps curl  0.536823  0.394492         0.579151         0.448345   \n",
            "1  barbell biceps curl  0.644883  0.471560         0.697117         0.534556   \n",
            "2  barbell biceps curl  0.644585  0.459688         0.698101         0.534154   \n",
            "3  barbell biceps curl  0.639845  0.447251         0.693448         0.527830   \n",
            "4  barbell biceps curl  0.638382  0.440549         0.692775         0.526917   \n",
            "\n",
            "   right_shoulder_x  right_shoulder_y  right_elbow_x  right_elbow_y  \\\n",
            "0          0.494607          0.456272       0.487493       0.566115   \n",
            "1          0.597209          0.541820       0.591782       0.674158   \n",
            "2          0.599484          0.542223       0.592465       0.670539   \n",
            "3          0.593281          0.536076       0.587828       0.666124   \n",
            "4          0.592473          0.536303       0.586838       0.667377   \n",
            "\n",
            "   left_elbow_x  ...  left_ankle_x  left_ankle_y  \\\n",
            "0      0.592113  ...      0.565274      0.988899   \n",
            "1      0.708641  ...      0.671295      0.920119   \n",
            "2      0.708947  ...      0.671020      0.905485   \n",
            "3      0.704632  ...      0.671570      0.784042   \n",
            "4      0.703783  ...      0.669120      0.898985   \n",
            "\n",
            "   LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_sin  \\\n",
            "0                                       0.736322   \n",
            "1                                       0.453680   \n",
            "2                                       0.711619   \n",
            "3                                       0.661952   \n",
            "4                                       0.762601   \n",
            "\n",
            "   LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_cos  \\\n",
            "0                                       0.676631   \n",
            "1                                      -0.891165   \n",
            "2                                      -0.702565   \n",
            "3                                      -0.749546   \n",
            "4                                      -0.646869   \n",
            "\n",
            "   RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_sin  \\\n",
            "0                                          0.924514   \n",
            "1                                          0.915820   \n",
            "2                                          0.539395   \n",
            "3                                          0.996717   \n",
            "4                                          0.873454   \n",
            "\n",
            "   RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_cos  \\\n",
            "0                                          0.381147   \n",
            "1                                         -0.401590   \n",
            "2                                         -0.842053   \n",
            "3                                          0.080968   \n",
            "4                                         -0.486906   \n",
            "\n",
            "   LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_sin  \\\n",
            "0                                 0.566051   \n",
            "1                                -0.941027   \n",
            "2                                 0.570783   \n",
            "3                                 0.971529   \n",
            "4                                -0.815144   \n",
            "\n",
            "   LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_cos  \\\n",
            "0                                -0.824370   \n",
            "1                                -0.338330   \n",
            "2                                 0.821101   \n",
            "3                                 0.236920   \n",
            "4                                 0.579258   \n",
            "\n",
            "   RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_sin  \\\n",
            "0                                    0.727394   \n",
            "1                                    0.981156   \n",
            "2                                    0.965533   \n",
            "3                                    0.732141   \n",
            "4                                   -0.918831   \n",
            "\n",
            "   RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_cos  \n",
            "0                                    0.686220  \n",
            "1                                    0.193218  \n",
            "2                                    0.260279  \n",
            "3                                   -0.681154  \n",
            "4                                   -0.394652  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "df=data[['label',\n",
        "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle',\n",
        "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle',\n",
        "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle',\n",
        "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle']]\n",
        "def normalize_angles(df):\n",
        "    \"\"\"\n",
        "    Normalise les angles articulaires entre -1 et 1 en conservant la relation cyclique des angles\n",
        "    \"\"\"\n",
        "    # Création d'une copie pour ne pas modifier l'original\n",
        "    normalized_df = df.copy()\n",
        "\n",
        "    # Normalisation sinus/cosinus pour préserver la circularité des angles\n",
        "    for col in ['LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle',\n",
        "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle',\n",
        "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle',\n",
        "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle']:\n",
        "        # Conversion en radians\n",
        "        # Normalisation circulaire\n",
        "        normalized_df[col+'_sin']= np.sin(normalized_df[col])\n",
        "        normalized_df[col+'_cos']= np.cos(normalized_df[col])\n",
        "\n",
        "        # Suppression de la colonne originale\n",
        "        normalized_df.drop(col, axis=1, inplace=True)\n",
        "\n",
        "    return normalized_df\n",
        "df=normalize_angles(df)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDAbxg0r2c1D",
        "outputId": "7f106479-8bce-4b95-98b3-073a224df3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['label', 'nose_x', 'nose_y', 'left_shoulder_x', 'left_shoulder_y',\n",
            "       'right_shoulder_x', 'right_shoulder_y', 'right_elbow_x',\n",
            "       'right_elbow_y', 'left_elbow_x', 'left_elbow_y', 'right_wrist_x',\n",
            "       'right_wrist_y', 'left_wrist_x', 'left_wrist_y', 'left_hip_x',\n",
            "       'left_hip_y', 'right_hip_x', 'right_hip_y', 'right_knee_x',\n",
            "       'right_knee_y', 'left_knee_x', 'left_knee_y', 'right_ankle_x',\n",
            "       'right_ankle_y', 'left_ankle_x', 'left_ankle_y',\n",
            "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_sin',\n",
            "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_cos',\n",
            "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_sin',\n",
            "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_cos',\n",
            "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_sin',\n",
            "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_cos',\n",
            "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_sin',\n",
            "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_cos'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creation du dexième modèle:"
      ],
      "metadata": {
        "id": "vidsdR0TqaHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KIy3qMxNqV1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTG2brFJC196"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "def create_ultralight_model(sequence_length=30, n_features=8, n_classes=4):\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=(sequence_length, n_features)),\n",
        "        Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR7gy6_eGz67"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_data(df):\n",
        "    # Extraire les features et labels\n",
        "    X = df.drop('label', axis=1).values\n",
        "    y = df['label'].values\n",
        "\n",
        "    # Encoder les labels using the global le\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Paramètres\n",
        "    sequence_length = 30 # nombre de frames par séquence\n",
        "\n",
        "    # Construction des séquences cohérentes\n",
        "    X_sequences = []\n",
        "    y_sequences = []\n",
        "\n",
        "    # On parcourt les données pour créer des séquences de frames du même label\n",
        "    for i in range(len(X) - sequence_length):\n",
        "        # Vérifier que toutes les frames appartiennent au même label\n",
        "        if len(set(y[i:i+sequence_length])) == 1:\n",
        "            X_sequences.append(X[i:i+sequence_length])\n",
        "            y_sequences.append(y_encoded[i])\n",
        "\n",
        "    X_sequences = np.array(X_sequences)\n",
        "    y_sequences = np.array(y_sequences)\n",
        "\n",
        "    print(\"Shape des données LSTM : \", X_sequences.shape)  # (nb_sequences, 30, nb_features)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "entrainement du deuxième modèle:"
      ],
      "metadata": {
        "id": "CDj5mzCgq0OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "X_train, X_test, y_train, y_test=prepare_data(df)\n",
        "model = create_ultralight_model()\n",
        "model.summary()\n",
        "# Entraînement\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',    # Métrique à surveiller\n",
        "    patience=10,          # Nombre d'epochs sans amélioration avant arrêt\n",
        "    restore_best_weights=True  # Restaure les poids du meilleur modèle\n",
        ")\n",
        "\n",
        "# Entraînement du modèle avec EarlyStopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=41,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]  # Ajout du callback\n",
        ")"
      ],
      "metadata": {
        "id": "EX_Bby41quhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT36upn20oi1"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/SportActivityDataset/clean_data/model14.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}