{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWKAve_H-bp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oASQYFTFkbPS"
      },
      "source": [
        "Step 1: Upload or Collect Video Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FSrGgiSCSQx",
        "outputId": "bd8a2dc9-edd3-4eb6-c72b-1c082be37271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe\n",
        "!pip install pandas\n",
        "!pip install  numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPTPudmnYBfR",
        "outputId": "fb4ce9a0-f514-4381-d884-6bf92f43238c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['push-up', 'shoulder press', 'squat', 'barbell biceps curl', 'lstm_model222.keras', 'lstm_model29.keras', 'lstm_model33.keras', 'model12.keras', 'model13.keras']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "output_csv = '/content/drive/MyDrive/output/keypoints6.csv'\n",
        "data_path = '/content/drive/MyDrive/SportActivityDataset/'\n",
        "activities = os.listdir(data_path)\n",
        "print(activities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxwkrfbTkC2y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mediapipe as mp\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Initialisation MediaPipe\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "# les Landmarks importants\n",
        "IMPORTANT_LMS = [\n",
        "    \"NOSE\",\n",
        "    \"LEFT_SHOULDER\",\n",
        "    \"RIGHT_SHOULDER\",\n",
        "    \"RIGHT_ELBOW\",\n",
        "    \"LEFT_ELBOW\",\n",
        "    \"RIGHT_WRIST\",\n",
        "    \"LEFT_WRIST\",\n",
        "    \"LEFT_HIP\",\n",
        "    \"RIGHT_HIP\",\"RIGHT_KNEE\",\"LEFT_KNEE\",\"RIGHT_ANKLE\",\"LEFT_ANKLE\"\n",
        "]\n",
        "#les  angles importants\n",
        "ANGLE_JOINTS = [\n",
        "    (\"LEFT_SHOULDER\", \"LEFT_ELBOW\", \"LEFT_WRIST\"),\n",
        "    (\"RIGHT_SHOULDER\", \"RIGHT_ELBOW\", \"RIGHT_WRIST\"),\n",
        "    (\"LEFT_HIP\", \"LEFT_KNEE\", \"LEFT_ANKLE\"),\n",
        "    (\"RIGHT_HIP\", \"RIGHT_KNEE\", \"RIGHT_ANKLE\")\n",
        "]\n",
        "# Cr√©ation les colonnes du CSV\n",
        "angle_headers = [f\"{a}_{b}_{c}_angle\" for a, b, c in ANGLE_JOINTS]\n",
        "HEADERS = [\"label\"]\n",
        "\n",
        "for lm in IMPORTANT_LMS:\n",
        "    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]\n",
        "\n",
        "HEADERS = HEADERS+ angle_headers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GFImorYkjVO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N17App5-j-a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "#fonction to rescale the frame\n",
        "def rescale_frame(frame, percent=50):\n",
        "    width = int(frame.shape[1] * percent / 100)\n",
        "    height = int(frame.shape[0] * percent / 100)\n",
        "    dim = (width, height)\n",
        "    return cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
        "# Fonction pour extraire les keypoints\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Fonction pour extraire les keypoints d'une frame (utiliser dans le test)\n",
        "def extract_keypoints(image):\n",
        "    with mp_pose.Pose(static_image_mode=True) as pose:\n",
        "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        if not results.pose_landmarks:\n",
        "            return None\n",
        "\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "        keypoints = []\n",
        "\n",
        "        for lm in IMPORTANT_LMS:\n",
        "            point = landmarks[mp_pose.PoseLandmark[lm].value]\n",
        "            keypoints.append([point.x, point.y, point.z, point.visibility])\n",
        "\n",
        "        normalized_keypoints = normalize_keypoints(keypoints)\n",
        "        normalized_keypoints = np.array(normalized_keypoints).flatten()\n",
        "\n",
        "        # Calculate angles\n",
        "        angles = []\n",
        "        for joint1, joint2, joint3 in ANGLE_JOINTS:\n",
        "            a = landmarks[mp_pose.PoseLandmark[joint1].value]\n",
        "            b = landmarks[mp_pose.PoseLandmark[joint2].value]\n",
        "            c = landmarks[mp_pose.PoseLandmark[joint3].value]\n",
        "\n",
        "            angle = calculate_angle([a.x, a.y], [b.x, b.y], [c.x, c.y])\n",
        "            angles.append(angle)\n",
        "\n",
        "        # Concatenate keypoints and angles\n",
        "        all_features = np.concatenate([normalized_keypoints, angles])\n",
        "\n",
        "        return all_features\n",
        "\n",
        "\n",
        "\n",
        "# Fonction pour pr√©parer la s√©quence des keypoints (cette fonction est utiliser dans le test)\n",
        "def prepare_sequence(video_path, sequence_length=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Erreur lors de l'ouverture de la vid√©o.\")\n",
        "        return None\n",
        "\n",
        "    sequence = []\n",
        "\n",
        "    success, frame = cap.read()\n",
        "    while success:\n",
        "        keypoints = extract_features(frame)\n",
        "        if keypoints is not None:\n",
        "            sequence.append(keypoints)\n",
        "\n",
        "        if len(sequence) == sequence_length:\n",
        "            cap.release()\n",
        "            break\n",
        "\n",
        "        success, frame = cap.read()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if len(sequence) == sequence_length:\n",
        "        return np.array(sequence)  # Retourne une s√©quence compl√®te de keypoints\n",
        "    else:\n",
        "        return None  # Si la s√©quence est trop courte\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHGJuxNo6cmE",
        "outputId": "f8191353-d8c8-4648-ea55-e97551149e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['label', 'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle', 'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle', 'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle', 'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle']\n"
          ]
        }
      ],
      "source": [
        "print(HEADERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVRyBPPqkxnL"
      },
      "source": [
        "Step 4: Normalize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0ZNl9ZDkHEs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#normalizing keypoints coordinations\n",
        "def normalize_keypoints(keypoints):\n",
        "    keypoints = np.array(keypoints)\n",
        "    return (keypoints - np.min(keypoints)) / (np.max(keypoints) - np.min(keypoints))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTZPEHLaib5F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Initialiser le fichier CSV avec les headers si non existant\n",
        "def init_csv(dataset_path: str):\n",
        "    if os.path.exists(dataset_path):\n",
        "        return  # Ne rien faire si le fichier existe d√©j√†\n",
        "    with open(dataset_path, mode=\"w\", newline=\"\") as f:\n",
        "        csv_writer = csv.writer(f)\n",
        "        os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
        "        csv_writer.writerow(HEADERS)\n",
        "\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"\n",
        "    Calculate the angle between three points\n",
        "    a, b, c are each a list or array of [x, y]\n",
        "    Returns the angle in degrees\n",
        "    \"\"\"\n",
        "    a = np.array(a[:2])  # Only x and y\n",
        "    b = np.array(b[:2])\n",
        "    c = np.array(c[:2])\n",
        "\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "\n",
        "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
        "\n",
        "    return np.degrees(angle)\n",
        "\n",
        "# Enregistrer les keypoints + label dans le CSV\n",
        "def export_landmark_to_csv(dataset_path: str, results, label: str):\n",
        "    try:\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "        keypoints = []\n",
        "\n",
        "        for lm in IMPORTANT_LMS:\n",
        "            point = landmarks[mp_pose.PoseLandmark[lm].value]\n",
        "            keypoints.append([point.x, point.y, point.z, point.visibility])\n",
        "            normalized_keypoints = normalize_keypoints(keypoints)\n",
        "\n",
        "        keypoints_flat = list(np.array(normalized_keypoints).flatten())\n",
        "\n",
        "        # Add angle calculations\n",
        "        angles = []\n",
        "        for joint1, joint2, joint3 in ANGLE_JOINTS:\n",
        "            a = landmarks[mp_pose.PoseLandmark[joint1].value]\n",
        "            b = landmarks[mp_pose.PoseLandmark[joint2].value]\n",
        "            c = landmarks[mp_pose.PoseLandmark[joint3].value]\n",
        "\n",
        "            angle = calculate_angle(\n",
        "                [a.x, a.y], [b.x, b.y], [c.x, c.y]\n",
        "            )\n",
        "            angles.append(angle)\n",
        "\n",
        "        #all_features = [label] + keypoints_flat + angles\n",
        "        all_features = [label]+[landmarks[mp_pose.PoseLandmark[lm].value].x,landmarks[mp_pose.PoseLandmark[lm].value].y]+ angles # utiliser dans un test (√† supprimer !!)\n",
        "        with open(dataset_path, mode=\"a\", newline=\"\") as f:\n",
        "            csv_writer = csv.writer(f)\n",
        "            csv_writer.writerow(all_features)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Erreur:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Anf4amo7Tr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# Extraire les frames et enregistrer les keypoints dans le CSV\n",
        "def process_video(video_path, output_csv):\n",
        "    # Label = nom du dossier parent (= activit√©)\n",
        "    activity_label = os.path.basename(os.path.dirname(video_path))\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    pose = mp_pose.Pose()\n",
        "    while True:\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = pose.process(image_rgb)\n",
        "\n",
        "            if results.pose_landmarks:\n",
        "                  export_landmark_to_csv(output_csv, results, activity_label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    pose.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6GMT400vNT6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJr0H2Nfnwo8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Initialisation du fichier CSV une seule fois\n",
        "def create_the_csv_file():\n",
        "\n",
        " for activity in activities:\n",
        "    activity_path = os.path.join(data_path, activity)\n",
        "    videos = os.listdir(activity_path)\n",
        "    for video in videos:\n",
        "        video_path = os.path.join(activity_path, video)\n",
        "        process_video(video_path, output_csv)\n",
        "        print(\"Le dataset   des keypoints a √©t√© cr√©√© for \"+video_path)\n",
        "    print(\"Le dataset   des keypoints a √©t√© cr√©√© avec succ√®s fro \"+activity)\n",
        " print(\"Le dataset des keypoints a √©t√© cr√©√© avec succ√®s !\")\n",
        " return output_csv\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAGoquP3yIh9"
      },
      "source": [
        "2. Pr√©paration des donn√©es pour le mod√®le  dans la forme deq sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04rWaja6fY1P"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Define le as a global variable\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Charger le dataset\n",
        "def prepare_data(output_csv):\n",
        "    df = pd.read_csv(output_csv)\n",
        "\n",
        "    # Extraire les features et labels\n",
        "    X = df.drop('label', axis=1).values\n",
        "    y = df['label'].values\n",
        "\n",
        "    # Encoder les labels using the global le\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Param√®tres\n",
        "    sequence_length = 20  # nombre de frames par s√©quence\n",
        "\n",
        "    # Construction des s√©quences coh√©rentes\n",
        "    X_sequences = []\n",
        "    y_sequences = []\n",
        "\n",
        "    # On parcourt les donn√©es pour cr√©er des s√©quences de frames du m√™me label\n",
        "    for i in range(len(X) - sequence_length):\n",
        "        # V√©rifier que toutes les frames appartiennent au m√™me label\n",
        "        if len(set(y[i:i+sequence_length])) == 1:\n",
        "            X_sequences.append(X[i:i+sequence_length])\n",
        "            y_sequences.append(y_encoded[i])\n",
        "\n",
        "    X_sequences = np.array(X_sequences)\n",
        "    y_sequences = np.array(y_sequences)\n",
        "\n",
        "    print(\"Shape des donn√©es LSTM : \", X_sequences.shape)  # (nb_sequences, 30, nb_features)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation du premier mod√®le LSTM"
      ],
      "metadata": {
        "id": "vnKbAhlfpBdp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPu3H3zNyknX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Architecture du mod√®le LSTM\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, return_sequences=True, activation='tanh', input_shape=(sequence_length, X_train.shape[2])))\n",
        "    model.add(LSTM(128, return_sequences=False, activation='tanh'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(len(le.classes_), activation='softmax'))\n",
        "    # Compilation\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train, X_test, y_test):\n",
        "# Entra√Ænement avec batch_size\n",
        "  model.fit(X_train, y_train,\n",
        "          epochs=20,\n",
        "          batch_size=20,  # par exemple\n",
        "          validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tester le premier mod√®le\n"
      ],
      "metadata": {
        "id": "BdlB2gzgpMIb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk0lpD-D0ehN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whTZz5HIUlT_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "import mediapipe as mp\n",
        "\n",
        "# fonction pour faire la pr√©diction\n",
        "def predict_activity(video_path,model):\n",
        "\n",
        "# Pr√©parer la s√©quence de keypoints\n",
        "  sequence = prepare_sequence(video_path)\n",
        "\n",
        "  if sequence is not None:\n",
        "    # Reshaper la s√©quence pour qu'elle soit compatible avec l'entr√©e du mod√®le LSTM\n",
        "    sequence = sequence.reshape(1, sequence.shape[0], sequence.shape[1])  # (1, 30, 36)\n",
        "\n",
        "    # Pr√©diction\n",
        "    prediction = model.predict(sequence)\n",
        "\n",
        "    # D√©codage du label\n",
        "    predicted_label = np.argmax(prediction, axis=1)\n",
        "    predicted_label = le.inverse_transform(predicted_label)\n",
        "\n",
        "    # Afficher le r√©sultat\n",
        "     # D√©codage du label avec l'encodeur\n",
        "    print(f\"L'activit√© pr√©dite est : {predicted_label}\")\n",
        "  else:\n",
        "    print(\"La s√©quence est trop courte ou aucun keypoint d√©tect√© dans la vid√©o.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_a8p38MN2c4"
      },
      "outputs": [],
      "source": [
        "#preparing train and test data\n",
        "\n",
        "#output_csv = '/content/drive/MyDrive/output/keypoints7.csv'\n",
        "\n",
        "#print(X_train.shape[2])\n",
        "#print(y_test[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T0e4D2TPOJg"
      },
      "outputs": [],
      "source": [
        "#create_lstm_model\n",
        "#model=create_lstm_model(X_train.shape)\n",
        "#train the model\n",
        "#train_model(model, X_train, y_train, X_test, y_test)\n",
        "#save the model\n",
        "#model.save('/content/drive/MyDrive/SportActivityDataset/DATA/final_lstm_mode.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otATEH_KXjws",
        "outputId": "83d06b04-0299-40a4-e15e-d2b5b7c4e632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "sequence_length=30\n",
        "#load the model\n",
        "\n",
        "le.fit_transform(['barbell biceps curl', 'push-up', 'shoulder press', 'squat'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualize the data and clean it for better results"
      ],
      "metadata": {
        "id": "ZZBsBEzups1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCfXD2xjAgOM",
        "outputId": "88b10c15-3dd8-4494-9c21-5794164ed37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x',\n",
            "       'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v',\n",
            "       'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z',\n",
            "       'right_shoulder_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z',\n",
            "       'right_elbow_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z',\n",
            "       'left_elbow_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z',\n",
            "       'right_wrist_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z',\n",
            "       'left_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v',\n",
            "       'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v',\n",
            "       'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v',\n",
            "       'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v',\n",
            "       'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v',\n",
            "       'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v',\n",
            "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle',\n",
            "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle',\n",
            "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle',\n",
            "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle'],\n",
            "      dtype='object')\n",
            "['barbell biceps curl' 'push-up' 'shoulder press' 'squat']\n",
            "                label    nose_x    nose_y    nose_z    nose_v  \\\n",
            "28565  shoulder press  0.578683  0.477942  0.185670  0.868902   \n",
            "28566  shoulder press  0.575887  0.474537  0.196246  0.865325   \n",
            "28567  shoulder press  0.574833  0.472620  0.195467  0.863809   \n",
            "28568  shoulder press  0.575136  0.472969  0.194872  0.863441   \n",
            "28569  shoulder press  0.571817  0.468718  0.190299  0.862449   \n",
            "\n",
            "       left_shoulder_x  left_shoulder_y  left_shoulder_z  left_shoulder_v  \\\n",
            "28565         0.624617         0.568095         0.261009         0.868879   \n",
            "28566         0.622518         0.564100         0.257165         0.865301   \n",
            "28567         0.621705         0.562246         0.253842         0.863785   \n",
            "28568         0.622249         0.562573         0.252141         0.863416   \n",
            "28569         0.619648         0.559179         0.248959         0.862423   \n",
            "\n",
            "       right_shoulder_x  ...  right_ankle_z  right_ankle_v  left_ankle_x  \\\n",
            "28565          0.551125  ...       0.281446       0.530271      0.552430   \n",
            "28566          0.548420  ...       0.285338       0.523949      0.550682   \n",
            "28567          0.547522  ...       0.279107       0.517795      0.550711   \n",
            "28568          0.547899  ...       0.273700       0.512834      0.553029   \n",
            "28569          0.544338  ...       0.267387       0.504688      0.551583   \n",
            "\n",
            "       left_ankle_y  left_ankle_z  left_ankle_v  \\\n",
            "28565           1.0      0.122351      0.805174   \n",
            "28566           1.0      0.115982      0.791783   \n",
            "28567           1.0      0.112505      0.778751   \n",
            "28568           1.0      0.110965      0.766617   \n",
            "28569           1.0      0.107670      0.753499   \n",
            "\n",
            "       LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle  \\\n",
            "28565                                  19.083937   \n",
            "28566                                  17.064076   \n",
            "28567                                  16.312477   \n",
            "28568                                  16.257691   \n",
            "28569                                  17.379431   \n",
            "\n",
            "       RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle  \\\n",
            "28565                                     36.496826   \n",
            "28566                                     36.592782   \n",
            "28567                                     36.899752   \n",
            "28568                                     37.181749   \n",
            "28569                                     37.214496   \n",
            "\n",
            "       LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle  \\\n",
            "28565                           163.673577   \n",
            "28566                           164.679290   \n",
            "28567                           164.503712   \n",
            "28568                           164.378991   \n",
            "28569                           164.677381   \n",
            "\n",
            "       RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle  \n",
            "28565                              124.751898  \n",
            "28566                              123.877309  \n",
            "28567                              123.368707  \n",
            "28568                              122.456429  \n",
            "28569                              121.494714  \n",
            "\n",
            "[5 rows x 57 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/output/keypoints6.csv')\n",
        "print(df.columns)\n",
        "data=df[df['label']!='hammer curl']\n",
        "print(data['label'].unique())\n",
        "print(data[data['label']=='shoulder press'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "changer la structure de data pour un meilleur entrainement"
      ],
      "metadata": {
        "id": "Vv4G8zAQqOlJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA1gOZcwNmAs",
        "outputId": "85958862-3b02-40e2-d1a4-47a4bec57ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 label    nose_x    nose_y  left_shoulder_x  left_shoulder_y  \\\n",
            "0  barbell biceps curl  0.536823  0.394492         0.579151         0.448345   \n",
            "1  barbell biceps curl  0.644883  0.471560         0.697117         0.534556   \n",
            "2  barbell biceps curl  0.644585  0.459688         0.698101         0.534154   \n",
            "3  barbell biceps curl  0.639845  0.447251         0.693448         0.527830   \n",
            "4  barbell biceps curl  0.638382  0.440549         0.692775         0.526917   \n",
            "\n",
            "   right_shoulder_x  right_shoulder_y  right_elbow_x  right_elbow_y  \\\n",
            "0          0.494607          0.456272       0.487493       0.566115   \n",
            "1          0.597209          0.541820       0.591782       0.674158   \n",
            "2          0.599484          0.542223       0.592465       0.670539   \n",
            "3          0.593281          0.536076       0.587828       0.666124   \n",
            "4          0.592473          0.536303       0.586838       0.667377   \n",
            "\n",
            "   left_elbow_x  ...  left_ankle_x  left_ankle_y  \\\n",
            "0      0.592113  ...      0.565274      0.988899   \n",
            "1      0.708641  ...      0.671295      0.920119   \n",
            "2      0.708947  ...      0.671020      0.905485   \n",
            "3      0.704632  ...      0.671570      0.784042   \n",
            "4      0.703783  ...      0.669120      0.898985   \n",
            "\n",
            "   LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_sin  \\\n",
            "0                                       0.736322   \n",
            "1                                       0.453680   \n",
            "2                                       0.711619   \n",
            "3                                       0.661952   \n",
            "4                                       0.762601   \n",
            "\n",
            "   LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_cos  \\\n",
            "0                                       0.676631   \n",
            "1                                      -0.891165   \n",
            "2                                      -0.702565   \n",
            "3                                      -0.749546   \n",
            "4                                      -0.646869   \n",
            "\n",
            "   RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_sin  \\\n",
            "0                                          0.924514   \n",
            "1                                          0.915820   \n",
            "2                                          0.539395   \n",
            "3                                          0.996717   \n",
            "4                                          0.873454   \n",
            "\n",
            "   RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_cos  \\\n",
            "0                                          0.381147   \n",
            "1                                         -0.401590   \n",
            "2                                         -0.842053   \n",
            "3                                          0.080968   \n",
            "4                                         -0.486906   \n",
            "\n",
            "   LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_sin  \\\n",
            "0                                 0.566051   \n",
            "1                                -0.941027   \n",
            "2                                 0.570783   \n",
            "3                                 0.971529   \n",
            "4                                -0.815144   \n",
            "\n",
            "   LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_cos  \\\n",
            "0                                -0.824370   \n",
            "1                                -0.338330   \n",
            "2                                 0.821101   \n",
            "3                                 0.236920   \n",
            "4                                 0.579258   \n",
            "\n",
            "   RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_sin  \\\n",
            "0                                    0.727394   \n",
            "1                                    0.981156   \n",
            "2                                    0.965533   \n",
            "3                                    0.732141   \n",
            "4                                   -0.918831   \n",
            "\n",
            "   RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_cos  \n",
            "0                                    0.686220  \n",
            "1                                    0.193218  \n",
            "2                                    0.260279  \n",
            "3                                   -0.681154  \n",
            "4                                   -0.394652  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "df=data[['label',\n",
        "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle',\n",
        "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle',\n",
        "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle',\n",
        "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle']]\n",
        "def normalize_angles(df):\n",
        "    \"\"\"\n",
        "    Normalise les angles articulaires entre -1 et 1 en conservant la relation cyclique des angles\n",
        "    \"\"\"\n",
        "    # Cr√©ation d'une copie pour ne pas modifier l'original\n",
        "    normalized_df = df.copy()\n",
        "\n",
        "    # Normalisation sinus/cosinus pour pr√©server la circularit√© des angles\n",
        "    for col in ['LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle',\n",
        "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle',\n",
        "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle',\n",
        "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle']:\n",
        "        # Conversion en radians\n",
        "        # Normalisation circulaire\n",
        "        normalized_df[col+'_sin']= np.sin(normalized_df[col])\n",
        "        normalized_df[col+'_cos']= np.cos(normalized_df[col])\n",
        "\n",
        "        # Suppression de la colonne originale\n",
        "        normalized_df.drop(col, axis=1, inplace=True)\n",
        "\n",
        "    return normalized_df\n",
        "df=normalize_angles(df)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDAbxg0r2c1D",
        "outputId": "7f106479-8bce-4b95-98b3-073a224df3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['label', 'nose_x', 'nose_y', 'left_shoulder_x', 'left_shoulder_y',\n",
            "       'right_shoulder_x', 'right_shoulder_y', 'right_elbow_x',\n",
            "       'right_elbow_y', 'left_elbow_x', 'left_elbow_y', 'right_wrist_x',\n",
            "       'right_wrist_y', 'left_wrist_x', 'left_wrist_y', 'left_hip_x',\n",
            "       'left_hip_y', 'right_hip_x', 'right_hip_y', 'right_knee_x',\n",
            "       'right_knee_y', 'left_knee_x', 'left_knee_y', 'right_ankle_x',\n",
            "       'right_ankle_y', 'left_ankle_x', 'left_ankle_y',\n",
            "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_sin',\n",
            "       'LEFT_SHOULDER_LEFT_ELBOW_LEFT_WRIST_angle_cos',\n",
            "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_sin',\n",
            "       'RIGHT_SHOULDER_RIGHT_ELBOW_RIGHT_WRIST_angle_cos',\n",
            "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_sin',\n",
            "       'LEFT_HIP_LEFT_KNEE_LEFT_ANKLE_angle_cos',\n",
            "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_sin',\n",
            "       'RIGHT_HIP_RIGHT_KNEE_RIGHT_ANKLE_angle_cos'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creation du dexi√®me mod√®le:"
      ],
      "metadata": {
        "id": "vidsdR0TqaHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KIy3qMxNqV1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTG2brFJC196"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "def create_ultralight_model(sequence_length=30, n_features=8, n_classes=4):\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=(sequence_length, n_features)),\n",
        "        Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR7gy6_eGz67"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_data(df):\n",
        "    # Extraire les features et labels\n",
        "    X = df.drop('label', axis=1).values\n",
        "    y = df['label'].values\n",
        "\n",
        "    # Encoder les labels using the global le\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Param√®tres\n",
        "    sequence_length = 30 # nombre de frames par s√©quence\n",
        "\n",
        "    # Construction des s√©quences coh√©rentes\n",
        "    X_sequences = []\n",
        "    y_sequences = []\n",
        "\n",
        "    # On parcourt les donn√©es pour cr√©er des s√©quences de frames du m√™me label\n",
        "    for i in range(len(X) - sequence_length):\n",
        "        # V√©rifier que toutes les frames appartiennent au m√™me label\n",
        "        if len(set(y[i:i+sequence_length])) == 1:\n",
        "            X_sequences.append(X[i:i+sequence_length])\n",
        "            y_sequences.append(y_encoded[i])\n",
        "\n",
        "    X_sequences = np.array(X_sequences)\n",
        "    y_sequences = np.array(y_sequences)\n",
        "\n",
        "    print(\"Shape des donn√©es LSTM : \", X_sequences.shape)  # (nb_sequences, 30, nb_features)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "entrainement du deuxi√®me mod√®le:"
      ],
      "metadata": {
        "id": "CDj5mzCgq0OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "X_train, X_test, y_train, y_test=prepare_data(df)\n",
        "model = create_ultralight_model()\n",
        "model.summary()\n",
        "# Entra√Ænement\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',    # M√©trique √† surveiller\n",
        "    patience=10,          # Nombre d'epochs sans am√©lioration avant arr√™t\n",
        "    restore_best_weights=True  # Restaure les poids du meilleur mod√®le\n",
        ")\n",
        "\n",
        "# Entra√Ænement du mod√®le avec EarlyStopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=41,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]  # Ajout du callback\n",
        ")"
      ],
      "metadata": {
        "id": "EX_Bby41quhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT36upn20oi1"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/SportActivityDataset/clean_data/model14.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}